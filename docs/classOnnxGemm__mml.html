<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ModularML: OnnxGemm_mml&lt; T &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">ModularML
   </div>
   <div id="projectbrief">Machine learning framework in C++</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classOnnxGemm__mml-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">OnnxGemm_mml&lt; T &gt; Class Template Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for OnnxGemm_mml&lt; T &gt;:</div>
<div class="dyncontent">
<div class="center"><img src="classOnnxGemm__mml__inherit__graph.png" border="0" usemap="#aOnnxGemm__mml_3_01T_01_4_inherit__map" alt="Inheritance graph"/></div>
<map name="aOnnxGemm__mml_3_01T_01_4_inherit__map" id="aOnnxGemm__mml_3_01T_01_4_inherit__map">
<area shape="rect" title=" " alt="" coords="11,79,186,104"/>
<area shape="rect" href="classOnnxGemmModule.html" title="Abstract class for classes that contain standard GEMM functions using the ONNX GEMM format." alt="" coords="5,5,192,31"/>
<area shape="poly" title=" " alt="" coords="101,44,101,79,96,79,96,44"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for OnnxGemm_mml&lt; T &gt;:</div>
<div class="dyncontent">
<div class="center"><img src="classOnnxGemm__mml__coll__graph.png" border="0" usemap="#aOnnxGemm__mml_3_01T_01_4_coll__map" alt="Collaboration graph"/></div>
<map name="aOnnxGemm__mml_3_01T_01_4_coll__map" id="aOnnxGemm__mml_3_01T_01_4_coll__map">
<area shape="rect" title=" " alt="" coords="11,79,186,104"/>
<area shape="rect" href="classOnnxGemmModule.html" title="Abstract class for classes that contain standard GEMM functions using the ONNX GEMM format." alt="" coords="5,5,192,31"/>
<area shape="poly" title=" " alt="" coords="101,44,101,79,96,79,96,44"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a47d3e5beadcf04bcdd226e9f5fe0cc52" id="r_a47d3e5beadcf04bcdd226e9f5fe0cc52"><td class="memItemLeft" align="right" valign="top"><a id="a47d3e5beadcf04bcdd226e9f5fe0cc52" name="a47d3e5beadcf04bcdd226e9f5fe0cc52"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OnnxGemm_mml</b> (const <a class="el" href="classOnnxGemm__mml.html">OnnxGemm_mml</a> &amp;other)=default</td></tr>
<tr class="separator:a47d3e5beadcf04bcdd226e9f5fe0cc52"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7a0cd2841fbf53a83e47291aad8d4cb7" id="r_a7a0cd2841fbf53a83e47291aad8d4cb7"><td class="memItemLeft" align="right" valign="top"><a id="a7a0cd2841fbf53a83e47291aad8d4cb7" name="a7a0cd2841fbf53a83e47291aad8d4cb7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>OnnxGemm_mml</b> (<a class="el" href="classOnnxGemm__mml.html">OnnxGemm_mml</a> &amp;&amp;other) noexcept=default</td></tr>
<tr class="separator:a7a0cd2841fbf53a83e47291aad8d4cb7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a07b6b0b3730386cbdb554ac8d350a610" id="r_a07b6b0b3730386cbdb554ac8d350a610"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOnnxGemm__mml.html#a07b6b0b3730386cbdb554ac8d350a610">gemm_inner_product</a> (std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; A=nullptr, std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; B=nullptr, float alpha=1.0, float beta=1.0, int transA=0, int transB=0, std::optional&lt; std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; &gt; C=std::nullopt) override</td></tr>
<tr class="memdesc:a07b6b0b3730386cbdb554ac8d350a610"><td class="mdescLeft">&#160;</td><td class="mdescRight">Basic CPU implementation of GEMM, with the inner product approach. Performs operation Y := alpha * A * B + beta * C (std::optional) More detailed info in <a href="https://onnx.ai/onnx/operators/onnx__Gemm.html">https://onnx.ai/onnx/operators/onnx__Gemm.html</a>.  <br /></td></tr>
<tr class="separator:a07b6b0b3730386cbdb554ac8d350a610"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac127bb22c7620ca154edc87d4ccb228a" id="r_ac127bb22c7620ca154edc87d4ccb228a"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOnnxGemm__mml.html#ac127bb22c7620ca154edc87d4ccb228a">gemm_outer_product</a> (std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; A=nullptr, std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; B=nullptr, float alpha=1.0, float beta=1.0, int transA=0, int transB=0, std::optional&lt; std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; &gt; C=std::nullopt) override</td></tr>
<tr class="memdesc:ac127bb22c7620ca154edc87d4ccb228a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Basic CPU implementation of GEMM, with the outer product approach. Performs operation Y := alpha * A * B + beta * C (std::optional) More detailed info in <a href="https://onnx.ai/onnx/operators/onnx__Gemm.html">https://onnx.ai/onnx/operators/onnx__Gemm.html</a>.  <br /></td></tr>
<tr class="separator:ac127bb22c7620ca154edc87d4ccb228a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a788ad2eb9ee693102e70a63fb53f27a6" id="r_a788ad2eb9ee693102e70a63fb53f27a6"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOnnxGemm__mml.html#a788ad2eb9ee693102e70a63fb53f27a6">gemm_row_wise_product</a> (std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; A=nullptr, std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; B=nullptr, float alpha=1.0, float beta=1.0, int transA=0, int transB=0, std::optional&lt; std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; &gt; C=std::nullopt) override</td></tr>
<tr class="memdesc:a788ad2eb9ee693102e70a63fb53f27a6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Basic CPU implementation of GEMM, with the row-wise product approach. Performs operation Y := alpha * A * B + beta * C (std::optional) More detailed info in <a href="https://onnx.ai/onnx/operators/onnx__Gemm.html">https://onnx.ai/onnx/operators/onnx__Gemm.html</a>.  <br /></td></tr>
<tr class="separator:a788ad2eb9ee693102e70a63fb53f27a6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab85aea5631b945ef9fccc28be5e4fc8d" id="r_ab85aea5631b945ef9fccc28be5e4fc8d"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOnnxGemm__mml.html#ab85aea5631b945ef9fccc28be5e4fc8d">gemm_col_wise_product</a> (std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; A=nullptr, std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; B=nullptr, float alpha=1.0, float beta=1.0, int transA=0, int transB=0, std::optional&lt; std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; &gt; C=std::nullopt) override</td></tr>
<tr class="memdesc:ab85aea5631b945ef9fccc28be5e4fc8d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Basic CPU implementation of GEMM, with the col-wise product approach. Performs operation Y := alpha * A * B + beta * C (std::optional) More detailed info in <a href="https://onnx.ai/onnx/operators/onnx__Gemm.html">https://onnx.ai/onnx/operators/onnx__Gemm.html</a>.  <br /></td></tr>
<tr class="separator:ab85aea5631b945ef9fccc28be5e4fc8d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a11c09e1ea41495bbb2196bec667de65a" id="r_a11c09e1ea41495bbb2196bec667de65a"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOnnxGemm__mml.html#a11c09e1ea41495bbb2196bec667de65a">gemm_blocked</a> (std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; A=nullptr, std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; B=nullptr, float alpha=1.0, float beta=1.0, int transA=0, int transB=0, std::optional&lt; std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; &gt; C=std::nullopt) override</td></tr>
<tr class="memdesc:a11c09e1ea41495bbb2196bec667de65a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Blocked CPU implementation of GEMM. Performs operation Y := alpha * A * B + beta * C (std::optional) More detailed info in <a href="https://onnx.ai/onnx/operators/onnx__Gemm.html">https://onnx.ai/onnx/operators/onnx__Gemm.html</a>.  <br /></td></tr>
<tr class="separator:a11c09e1ea41495bbb2196bec667de65a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a27201ff1cefe8fb6fcb2ddb479561291" id="r_a27201ff1cefe8fb6fcb2ddb479561291"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOnnxGemm__mml.html#a27201ff1cefe8fb6fcb2ddb479561291">gemm_avx</a> (std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; A=nullptr, std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; B=nullptr, float alpha=1.0, float beta=1.0, int transA=0, int transB=0, std::optional&lt; std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; &gt; C=std::nullopt) override</td></tr>
<tr class="memdesc:a27201ff1cefe8fb6fcb2ddb479561291"><td class="mdescLeft">&#160;</td><td class="mdescRight">Vectorized implementation of GEMM using SIMD thanks to AVX. Performs operation Y := alpha * A * B + beta * C (std::optional) More detailed info in <a href="https://onnx.ai/onnx/operators/onnx__Gemm.html">https://onnx.ai/onnx/operators/onnx__Gemm.html</a>.  <br /></td></tr>
<tr class="separator:a27201ff1cefe8fb6fcb2ddb479561291"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5dbd02349a37226dcf8bd8afe83aacae" id="r_a5dbd02349a37226dcf8bd8afe83aacae"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOnnxGemm__mml.html#a5dbd02349a37226dcf8bd8afe83aacae">gemm_avx512</a> (std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; A=nullptr, std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; B=nullptr, float alpha=1.0, float beta=1.0, int transA=0, int transB=0, std::optional&lt; std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; &gt; C=std::nullopt) override</td></tr>
<tr class="memdesc:a5dbd02349a37226dcf8bd8afe83aacae"><td class="mdescLeft">&#160;</td><td class="mdescRight">Vectorized implementation of GEMM using SIMD thanks to AVX512. Performs operation Y := alpha * A * B + beta * C (std::optional) More detailed info in <a href="https://onnx.ai/onnx/operators/onnx__Gemm.html">https://onnx.ai/onnx/operators/onnx__Gemm.html</a>.  <br /></td></tr>
<tr class="separator:a5dbd02349a37226dcf8bd8afe83aacae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a59180ddf5bf859fd06d33678e999a926" id="r_a59180ddf5bf859fd06d33678e999a926"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOnnxGemm__mml.html#a59180ddf5bf859fd06d33678e999a926">gemm_intel_MKL</a> (std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; A=nullptr, std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; B=nullptr, float alpha=1.0, float beta=1.0, int transA=0, int transB=0, std::optional&lt; std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; &gt; C=std::nullopt) override</td></tr>
<tr class="memdesc:a59180ddf5bf859fd06d33678e999a926"><td class="mdescLeft">&#160;</td><td class="mdescRight">GEMM using Intel's Math Kernel Library. Performs operation Y := alpha * A * B + beta * C (std::optional) More detailed info in <a href="https://onnx.ai/onnx/operators/onnx__Gemm.html">https://onnx.ai/onnx/operators/onnx__Gemm.html</a>.  <br /></td></tr>
<tr class="separator:a59180ddf5bf859fd06d33678e999a926"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classOnnxGemmModule"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classOnnxGemmModule')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classOnnxGemmModule.html">OnnxGemmModule&lt; T &gt;</a></td></tr>
<tr class="memitem:aa0edfc6e2da94befc26a061fdde9c7ca inherit pub_methods_classOnnxGemmModule" id="r_aa0edfc6e2da94befc26a061fdde9c7ca"><td class="memItemLeft" align="right" valign="top">
&#160;</td><td class="memItemRight" valign="bottom"><b>OnnxGemmModule</b> ()=default</td></tr>
<tr class="memdesc:aa0edfc6e2da94befc26a061fdde9c7ca inherit pub_methods_classOnnxGemmModule"><td class="mdescLeft">&#160;</td><td class="mdescRight">Default constructor for GEMM class. <br /></td></tr>
<tr class="separator:aa0edfc6e2da94befc26a061fdde9c7ca inherit pub_methods_classOnnxGemmModule"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab5efe5a4149dae7eed97ef998ded69fb inherit pub_methods_classOnnxGemmModule" id="r_ab5efe5a4149dae7eed97ef998ded69fb"><td class="memItemLeft" align="right" valign="top">
&#160;</td><td class="memItemRight" valign="bottom"><b>OnnxGemmModule</b> (const <a class="el" href="classOnnxGemmModule.html">OnnxGemmModule</a> &amp;other)=default</td></tr>
<tr class="memdesc:ab5efe5a4149dae7eed97ef998ded69fb inherit pub_methods_classOnnxGemmModule"><td class="mdescLeft">&#160;</td><td class="mdescRight">Copy constructor for GEMM class. <br /></td></tr>
<tr class="separator:ab5efe5a4149dae7eed97ef998ded69fb inherit pub_methods_classOnnxGemmModule"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae3b9a7eb0189e40529a66462d18033cd inherit pub_methods_classOnnxGemmModule" id="r_ae3b9a7eb0189e40529a66462d18033cd"><td class="memItemLeft" align="right" valign="top">
&#160;</td><td class="memItemRight" valign="bottom"><b>OnnxGemmModule</b> (<a class="el" href="classOnnxGemmModule.html">OnnxGemmModule</a> &amp;&amp;other) noexcept=default</td></tr>
<tr class="memdesc:ae3b9a7eb0189e40529a66462d18033cd inherit pub_methods_classOnnxGemmModule"><td class="mdescLeft">&#160;</td><td class="mdescRight">Move constructor for GEMM class. <br /></td></tr>
<tr class="separator:ae3b9a7eb0189e40529a66462d18033cd inherit pub_methods_classOnnxGemmModule"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae4e6d9342ac2cf444bd57aab42802e37 inherit pub_methods_classOnnxGemmModule" id="r_ae4e6d9342ac2cf444bd57aab42802e37"><td class="memItemLeft" align="right" valign="top">
virtual&#160;</td><td class="memItemRight" valign="bottom"><b>~OnnxGemmModule</b> ()=default</td></tr>
<tr class="memdesc:ae4e6d9342ac2cf444bd57aab42802e37 inherit pub_methods_classOnnxGemmModule"><td class="mdescLeft">&#160;</td><td class="mdescRight">Abstract destructor for GEMM class. <br /></td></tr>
<tr class="separator:ae4e6d9342ac2cf444bd57aab42802e37 inherit pub_methods_classOnnxGemmModule"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a27201ff1cefe8fb6fcb2ddb479561291" name="a27201ff1cefe8fb6fcb2ddb479561291"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a27201ff1cefe8fb6fcb2ddb479561291">&#9670;&#160;</a></span>gemm_avx()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; <a class="el" href="classOnnxGemm__mml.html">OnnxGemm_mml</a>&lt; T &gt;::gemm_avx </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td>
          <td class="paramname"><em>A</em> = <code>nullptr</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td>
          <td class="paramname"><em>B</em> = <code>nullptr</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>beta</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>transA</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>transB</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::optional&lt; std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; &gt;&#160;</td>
          <td class="paramname"><em>C</em> = <code>std::nullopt</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Vectorized implementation of GEMM using SIMD thanks to AVX. Performs operation Y := alpha * A * B + beta * C (std::optional) More detailed info in <a href="https://onnx.ai/onnx/operators/onnx__Gemm.html">https://onnx.ai/onnx/operators/onnx__Gemm.html</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">A</td><td>Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M) if transA is non-zero. </td></tr>
    <tr><td class="paramname">B</td><td>Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K) if transB is non-zero. </td></tr>
    <tr><td class="paramname">alpha</td><td>Float alpha. </td></tr>
    <tr><td class="paramname">beta</td><td>Float beta. </td></tr>
    <tr><td class="paramname">transA</td><td>0 if matrix A is not transposed, 1 if matrix A is transposed. </td></tr>
    <tr><td class="paramname">transB</td><td>0 if matrix B is not transposed, 1 if matrix B is transposed. </td></tr>
    <tr><td class="paramname">C</td><td>Optional input tensor C. If not specified, the computation is done as if C is a scalar 0. The shape of C should be unidirectional broadcastable to (M, N). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Output tensor Y. Output tensor of shape (M, N). </dd></dl>

<p>Implements <a class="el" href="classOnnxGemmModule.html#aa7b14b51505429fb5f730078ef88ccb1">OnnxGemmModule&lt; T &gt;</a>.</p>

</div>
</div>
<a id="a5dbd02349a37226dcf8bd8afe83aacae" name="a5dbd02349a37226dcf8bd8afe83aacae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5dbd02349a37226dcf8bd8afe83aacae">&#9670;&#160;</a></span>gemm_avx512()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; <a class="el" href="classOnnxGemm__mml.html">OnnxGemm_mml</a>&lt; T &gt;::gemm_avx512 </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td>
          <td class="paramname"><em>A</em> = <code>nullptr</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td>
          <td class="paramname"><em>B</em> = <code>nullptr</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>beta</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>transA</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>transB</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::optional&lt; std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; &gt;&#160;</td>
          <td class="paramname"><em>C</em> = <code>std::nullopt</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Vectorized implementation of GEMM using SIMD thanks to AVX512. Performs operation Y := alpha * A * B + beta * C (std::optional) More detailed info in <a href="https://onnx.ai/onnx/operators/onnx__Gemm.html">https://onnx.ai/onnx/operators/onnx__Gemm.html</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">A</td><td>Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M) if transA is non-zero. </td></tr>
    <tr><td class="paramname">B</td><td>Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K) if transB is non-zero. </td></tr>
    <tr><td class="paramname">alpha</td><td>Float alpha. </td></tr>
    <tr><td class="paramname">beta</td><td>Float beta. </td></tr>
    <tr><td class="paramname">transA</td><td>0 if matrix A is not transposed, 1 if matrix A is transposed. </td></tr>
    <tr><td class="paramname">transB</td><td>0 if matrix B is not transposed, 1 if matrix B is transposed. </td></tr>
    <tr><td class="paramname">C</td><td>Optional input tensor C. If not specified, the computation is done as if C is a scalar 0. The shape of C should be unidirectional broadcastable to (M, N). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Output tensor Y. Output tensor of shape (M, N). </dd></dl>

<p>Implements <a class="el" href="classOnnxGemmModule.html#a6431aca2976ad9b453783855d01ba8c7">OnnxGemmModule&lt; T &gt;</a>.</p>

</div>
</div>
<a id="a11c09e1ea41495bbb2196bec667de65a" name="a11c09e1ea41495bbb2196bec667de65a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a11c09e1ea41495bbb2196bec667de65a">&#9670;&#160;</a></span>gemm_blocked()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; <a class="el" href="classOnnxGemm__mml.html">OnnxGemm_mml</a>&lt; T &gt;::gemm_blocked </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td>
          <td class="paramname"><em>A</em> = <code>nullptr</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td>
          <td class="paramname"><em>B</em> = <code>nullptr</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>beta</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>transA</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>transB</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::optional&lt; std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; &gt;&#160;</td>
          <td class="paramname"><em>C</em> = <code>std::nullopt</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Blocked CPU implementation of GEMM. Performs operation Y := alpha * A * B + beta * C (std::optional) More detailed info in <a href="https://onnx.ai/onnx/operators/onnx__Gemm.html">https://onnx.ai/onnx/operators/onnx__Gemm.html</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">A</td><td>Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M) if transA is non-zero. </td></tr>
    <tr><td class="paramname">B</td><td>Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K) if transB is non-zero. </td></tr>
    <tr><td class="paramname">alpha</td><td>Float alpha. </td></tr>
    <tr><td class="paramname">beta</td><td>Float beta. </td></tr>
    <tr><td class="paramname">transA</td><td>0 if matrix A is not transposed, 1 if matrix A is transposed. </td></tr>
    <tr><td class="paramname">transB</td><td>0 if matrix B is not transposed, 1 if matrix B is transposed. </td></tr>
    <tr><td class="paramname">C</td><td>Optional input tensor C. If not specified, the computation is done as if C is a scalar 0. The shape of C should be unidirectional broadcastable to (M, N). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Output tensor Y. Output tensor of shape (M, N). </dd></dl>

<p>Implements <a class="el" href="classOnnxGemmModule.html#a66f87218d36aa0037c37025bbbadf879">OnnxGemmModule&lt; T &gt;</a>.</p>

</div>
</div>
<a id="ab85aea5631b945ef9fccc28be5e4fc8d" name="ab85aea5631b945ef9fccc28be5e4fc8d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab85aea5631b945ef9fccc28be5e4fc8d">&#9670;&#160;</a></span>gemm_col_wise_product()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; <a class="el" href="classOnnxGemm__mml.html">OnnxGemm_mml</a>&lt; T &gt;::gemm_col_wise_product </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td>
          <td class="paramname"><em>A</em> = <code>nullptr</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td>
          <td class="paramname"><em>B</em> = <code>nullptr</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>beta</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>transA</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>transB</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::optional&lt; std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; &gt;&#160;</td>
          <td class="paramname"><em>C</em> = <code>std::nullopt</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Basic CPU implementation of GEMM, with the col-wise product approach. Performs operation Y := alpha * A * B + beta * C (std::optional) More detailed info in <a href="https://onnx.ai/onnx/operators/onnx__Gemm.html">https://onnx.ai/onnx/operators/onnx__Gemm.html</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">A</td><td>Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M) if transA is non-zero. </td></tr>
    <tr><td class="paramname">B</td><td>Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K) if transB is non-zero. </td></tr>
    <tr><td class="paramname">alpha</td><td>Float alpha. </td></tr>
    <tr><td class="paramname">beta</td><td>Float beta. </td></tr>
    <tr><td class="paramname">transA</td><td>0 if matrix A is not transposed, 1 if matrix A is transposed. </td></tr>
    <tr><td class="paramname">transB</td><td>0 if matrix B is not transposed, 1 if matrix B is transposed. </td></tr>
    <tr><td class="paramname">C</td><td>Optional input tensor C. If not specified, the computation is done as if C is a scalar 0. The shape of C should be unidirectional broadcastable to (M, N). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Output tensor Y. Output tensor of shape (M, N). </dd></dl>

<p>Implements <a class="el" href="classOnnxGemmModule.html#a4149164c8c131f1fd07ed8962c98957f">OnnxGemmModule&lt; T &gt;</a>.</p>

</div>
</div>
<a id="a07b6b0b3730386cbdb554ac8d350a610" name="a07b6b0b3730386cbdb554ac8d350a610"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a07b6b0b3730386cbdb554ac8d350a610">&#9670;&#160;</a></span>gemm_inner_product()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; <a class="el" href="classOnnxGemm__mml.html">OnnxGemm_mml</a>&lt; T &gt;::gemm_inner_product </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td>
          <td class="paramname"><em>A</em> = <code>nullptr</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td>
          <td class="paramname"><em>B</em> = <code>nullptr</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>beta</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>transA</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>transB</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::optional&lt; std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; &gt;&#160;</td>
          <td class="paramname"><em>C</em> = <code>std::nullopt</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Basic CPU implementation of GEMM, with the inner product approach. Performs operation Y := alpha * A * B + beta * C (std::optional) More detailed info in <a href="https://onnx.ai/onnx/operators/onnx__Gemm.html">https://onnx.ai/onnx/operators/onnx__Gemm.html</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">A</td><td>Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M) if transA is non-zero. </td></tr>
    <tr><td class="paramname">B</td><td>Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K) if transB is non-zero. </td></tr>
    <tr><td class="paramname">alpha</td><td>Float alpha. </td></tr>
    <tr><td class="paramname">beta</td><td>Float beta. </td></tr>
    <tr><td class="paramname">transA</td><td>0 if matrix A is not transposed, 1 if matrix A is transposed. </td></tr>
    <tr><td class="paramname">transB</td><td>0 if matrix B is not transposed, 1 if matrix B is transposed. </td></tr>
    <tr><td class="paramname">C</td><td>Optional input tensor C. If not specified, the computation is done as if C is a scalar 0. The shape of C should be unidirectional broadcastable to (M, N). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Output tensor Y. Output tensor of shape (M, N). </dd></dl>

<p>Implements <a class="el" href="classOnnxGemmModule.html#a25c0ad23ba44bfcf2492c735fba936b8">OnnxGemmModule&lt; T &gt;</a>.</p>

</div>
</div>
<a id="a59180ddf5bf859fd06d33678e999a926" name="a59180ddf5bf859fd06d33678e999a926"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a59180ddf5bf859fd06d33678e999a926">&#9670;&#160;</a></span>gemm_intel_MKL()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; <a class="el" href="classOnnxGemm__mml.html">OnnxGemm_mml</a>&lt; T &gt;::gemm_intel_MKL </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td>
          <td class="paramname"><em>A</em> = <code>nullptr</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td>
          <td class="paramname"><em>B</em> = <code>nullptr</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>beta</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>transA</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>transB</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::optional&lt; std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; &gt;&#160;</td>
          <td class="paramname"><em>C</em> = <code>std::nullopt</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>GEMM using Intel's Math Kernel Library. Performs operation Y := alpha * A * B + beta * C (std::optional) More detailed info in <a href="https://onnx.ai/onnx/operators/onnx__Gemm.html">https://onnx.ai/onnx/operators/onnx__Gemm.html</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">A</td><td>Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M) if transA is non-zero. </td></tr>
    <tr><td class="paramname">B</td><td>Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K) if transB is non-zero. </td></tr>
    <tr><td class="paramname">alpha</td><td>Float alpha. </td></tr>
    <tr><td class="paramname">beta</td><td>Float beta. </td></tr>
    <tr><td class="paramname">transA</td><td>0 if matrix A is not transposed, 1 if matrix A is transposed. </td></tr>
    <tr><td class="paramname">transB</td><td>0 if matrix B is not transposed, 1 if matrix B is transposed. </td></tr>
    <tr><td class="paramname">C</td><td>Optional input tensor C. If not specified, the computation is done as if C is a scalar 0. The shape of C should be unidirectional broadcastable to (M, N). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Output tensor Y. Output tensor of shape (M, N). </dd></dl>

<p>Implements <a class="el" href="classOnnxGemmModule.html#a3faef7daafa328ff756c82011f696ac2">OnnxGemmModule&lt; T &gt;</a>.</p>

</div>
</div>
<a id="ac127bb22c7620ca154edc87d4ccb228a" name="ac127bb22c7620ca154edc87d4ccb228a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac127bb22c7620ca154edc87d4ccb228a">&#9670;&#160;</a></span>gemm_outer_product()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; <a class="el" href="classOnnxGemm__mml.html">OnnxGemm_mml</a>&lt; T &gt;::gemm_outer_product </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td>
          <td class="paramname"><em>A</em> = <code>nullptr</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td>
          <td class="paramname"><em>B</em> = <code>nullptr</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>beta</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>transA</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>transB</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::optional&lt; std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; &gt;&#160;</td>
          <td class="paramname"><em>C</em> = <code>std::nullopt</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Basic CPU implementation of GEMM, with the outer product approach. Performs operation Y := alpha * A * B + beta * C (std::optional) More detailed info in <a href="https://onnx.ai/onnx/operators/onnx__Gemm.html">https://onnx.ai/onnx/operators/onnx__Gemm.html</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">A</td><td>Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M) if transA is non-zero. </td></tr>
    <tr><td class="paramname">B</td><td>Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K) if transB is non-zero. </td></tr>
    <tr><td class="paramname">alpha</td><td>Float alpha. </td></tr>
    <tr><td class="paramname">beta</td><td>Float beta. </td></tr>
    <tr><td class="paramname">transA</td><td>0 if matrix A is not transposed, 1 if matrix A is transposed. </td></tr>
    <tr><td class="paramname">transB</td><td>0 if matrix B is not transposed, 1 if matrix B is transposed. </td></tr>
    <tr><td class="paramname">C</td><td>Optional input tensor C. If not specified, the computation is done as if C is a scalar 0. The shape of C should be unidirectional broadcastable to (M, N). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Output tensor Y. Output tensor of shape (M, N). </dd></dl>

<p>Implements <a class="el" href="classOnnxGemmModule.html#a1e1d3203a01329443e9842d995ea0c9d">OnnxGemmModule&lt; T &gt;</a>.</p>

</div>
</div>
<a id="a788ad2eb9ee693102e70a63fb53f27a6" name="a788ad2eb9ee693102e70a63fb53f27a6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a788ad2eb9ee693102e70a63fb53f27a6">&#9670;&#160;</a></span>gemm_row_wise_product()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; <a class="el" href="classOnnxGemm__mml.html">OnnxGemm_mml</a>&lt; T &gt;::gemm_row_wise_product </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td>
          <td class="paramname"><em>A</em> = <code>nullptr</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt;&#160;</td>
          <td class="paramname"><em>B</em> = <code>nullptr</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>beta</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>transA</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>transB</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::optional&lt; std::shared_ptr&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T &gt; &gt; &gt;&#160;</td>
          <td class="paramname"><em>C</em> = <code>std::nullopt</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Basic CPU implementation of GEMM, with the row-wise product approach. Performs operation Y := alpha * A * B + beta * C (std::optional) More detailed info in <a href="https://onnx.ai/onnx/operators/onnx__Gemm.html">https://onnx.ai/onnx/operators/onnx__Gemm.html</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">A</td><td>Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M) if transA is non-zero. </td></tr>
    <tr><td class="paramname">B</td><td>Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K) if transB is non-zero. </td></tr>
    <tr><td class="paramname">alpha</td><td>Float alpha. </td></tr>
    <tr><td class="paramname">beta</td><td>Float beta. </td></tr>
    <tr><td class="paramname">transA</td><td>0 if matrix A is not transposed, 1 if matrix A is transposed. </td></tr>
    <tr><td class="paramname">transB</td><td>0 if matrix B is not transposed, 1 if matrix B is transposed. </td></tr>
    <tr><td class="paramname">C</td><td>Optional input tensor C. If not specified, the computation is done as if C is a scalar 0. The shape of C should be unidirectional broadcastable to (M, N). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Output tensor Y. Output tensor of shape (M, N). </dd></dl>

<p>Implements <a class="el" href="classOnnxGemmModule.html#ac69978f9125e3ee253c1cbf5ffa1e853">OnnxGemmModule&lt; T &gt;</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/home/runner/work/modularml/modularml/src/include/backend/<a class="el" href="mml__onnx__gemm_8hpp_source.html">mml_onnx_gemm.hpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
